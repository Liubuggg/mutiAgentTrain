environment:
  init_env_settings:
  - 4
  - 40
  num_charging_stations: 4
  observation_radius: 4
  reward_fn:
    charging: 0.1
    collision: -0.5
    complete_task: 5.0
    low_battery: -0.2
    move: -0.1
    stay_off_goal: -0.1
    stay_on_goal: 0.0
    step: -0.01

dhc:
  train:
    epochs: 1000
    learning_rate: 3e-4
    batch_size: 128
    buffer_capacity: 100000
    update_target_interval: 100
    save_interval: 50
    eval_interval: 50
  model:
    input_shape: [6, 9, 9]
    cnn_channels: 128
    hidden_dim: 256
    max_comm_agents: 3
    latent_dim: 784
    batch_size: 64
  communication:
    num_comm_heads: 4
    key_dim: 16
    comm_hidden_dim: 64

model:
  communication:
    comm_hidden_dim: 64
    key_dim: 16
    num_comm_heads: 4
  hidden_size: 64
  num_layers: 2

training:
  batch_size: 64
  buffer_capacity: 10000
  epochs: 10000
  eval_interval: 200
  learning_rate: 0.0001
  max_training_steps: 100
  save_interval: 500
  update_target_interval: 100
  train:
    batch_size: 64
    learning_rate: 0.0003
    num_epochs: 4
    gamma: 0.99
    clip_epsilon: 0.2
